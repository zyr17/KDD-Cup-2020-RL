{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/pkl/'\n",
    "min_gps = np.array([104.042102,30.652828])\n",
    "max_gps = np.array([104.129591,30.727818])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_data = pickle.load(open(folder + 'hex_grid.pkl', 'rb'))\n",
    "'''\n",
    "gx = np.array(grid_data['vertex'][:,:,0])\n",
    "gy = np.array(grid_data['vertex'][:,:,1])\n",
    "\n",
    "grid_data['vertex'][:,:,0] = gy\n",
    "grid_data['vertex'][:,:,1] = gx\n",
    "\n",
    "pickle.dump(grid_data, open(folder + 'hex_grid.pkl', 'wb'))\n",
    "'''\n",
    "'''\n",
    "grid_mean = np.array(grid_data['vertex'])\n",
    "grid_mean_x = grid_mean[:,:,0]\n",
    "grid_mean_y = grid_mean[:,:,1]\n",
    "grid_mean_x[grid_mean_x < min_gps[0]] = min_gps[0]\n",
    "grid_mean_y[grid_mean_y < min_gps[1]] = min_gps[1]\n",
    "grid_mean_x[grid_mean_x > max_gps[0]] = max_gps[0]\n",
    "grid_mean_y[grid_mean_y > max_gps[1]] = max_gps[1]\n",
    "print(grid_mean[:,:,0].min(),grid_mean[:,:,0].max())\n",
    "print(grid_mean[:,:,1].min(),grid_mean[:,:,1].max())\n",
    "grid_mean = grid_mean.mean(axis=1)\n",
    "grid_data['mean'] = grid_mean\n",
    "'''\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ride_req_data = pickle.load(open(folder + 'ride_req.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isRayIntersectsSegment(poi,s_poi,e_poi): #[x,y] [lng,lat]\n",
    "    #输入：判断点，边起点，边终点，都是[lng,lat]格式数组\n",
    "    if s_poi[1]==e_poi[1]: #排除与射线平行、重合，线段首尾端点重合的情况\n",
    "        return False\n",
    "    if s_poi[1]>poi[1] and e_poi[1]>poi[1]: #线段在射线上边\n",
    "        return False\n",
    "    if s_poi[1]<poi[1] and e_poi[1]<poi[1]: #线段在射线下边\n",
    "        return False\n",
    "    if s_poi[1]==poi[1] and e_poi[1]>poi[1]: #交点为下端点，对应spoint\n",
    "        return False\n",
    "    if e_poi[1]==poi[1] and s_poi[1]>poi[1]: #交点为下端点，对应epoint\n",
    "        return False\n",
    "    if s_poi[0]<poi[0] and e_poi[0]<poi[0]: #线段在射线左边\n",
    "        return False\n",
    "\n",
    "    xseg=e_poi[0]-(e_poi[0]-s_poi[0])*(e_poi[1]-poi[1])/(e_poi[1]-s_poi[1]) #求交\n",
    "    if xseg<poi[0]: #交点在射线起点的左侧\n",
    "        return False\n",
    "    return True  #排除上述情况之后\n",
    "\n",
    "def isPoiWithinPoly(poi,poly):\n",
    "    sinsc=0 #交点个数\n",
    "    poly = [*poly, poly[0]]\n",
    "    for s_poi, e_poi in zip(poly[:-1], poly[1:]): #[0,len-1]\n",
    "        if isRayIntersectsSegment(poi,s_poi,e_poi):\n",
    "            sinsc+=1 #有交点就加1\n",
    "\n",
    "    return True if sinsc%2==1 else  False\n",
    "\n",
    "def find_grid_idx(point, grid = grid_data):\n",
    "    res = -1\n",
    "    for i in range(len(grid['ID'])):\n",
    "        if isPoiWithinPoly(point, grid['vertex'][i]):\n",
    "            if res != -1:\n",
    "                print(res, i, point)\n",
    "            res = i\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_feat(ts):\n",
    "    lt = time.localtime(ts)\n",
    "    return lt.tm_mday, lt.tm_hour, lt.tm_wday, lt.tm_wday >= 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看数据分布。存在脏数据，碰到要忽略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7065937, 2, 2)\n",
      "(array([     163,        0,        0,        0,        0,        0,\n",
      "              0,        0, 14131702,        9]), array([  0.      ,  12.036152,  24.072304,  36.108456,  48.144608,\n",
      "        60.18076 ,  72.216912,  84.253064,  96.289216, 108.325368,\n",
      "       120.36152 ]))\n",
      "(array([     163,        0,        0,        0,        0,        3,\n",
      "              3, 14131701,        2,        2]), array([ 0.      ,  4.014547,  8.029094, 12.043641, 16.058188, 20.072735,\n",
      "       24.087282, 28.101829, 32.116376, 36.130923, 40.14547 ]))\n",
      "22.85281\n",
      "120.36612\n",
      "(8518, 6, 2)\n",
      "(array([50062,   940,    58,     0,     0,    12,     6,     6,    18,\n",
      "           6]), array([102.99358 , 104.730834, 106.468088, 108.205342, 109.942596,\n",
      "       111.67985 , 113.417104, 115.154358, 116.891612, 118.628866,\n",
      "       120.36612 ]))\n",
      "(array([   18,     6,     6,   131, 50881,    48,     6,     0,     0,\n",
      "          12]), array([22.85281 , 24.582904, 26.312998, 28.043092, 29.773186, 31.50328 ,\n",
      "       33.233374, 34.963468, 36.693562, 38.423656, 40.15375 ]))\n"
     ]
    }
   ],
   "source": [
    "ride_req_data['pos'].min(),ride_req_data['pos'].max()\n",
    "r = ride_req_data['pos']\n",
    "print(r.shape)\n",
    "print(np.histogram(r[:,:,0].reshape(-1)))\n",
    "print(np.histogram(r[:,:,1].reshape(-1)))\n",
    "print(grid_data['vertex'].min())\n",
    "print(grid_data['vertex'].max())\n",
    "v = grid_data['vertex']\n",
    "print(v.shape)\n",
    "print(np.histogram(v[:,:,0].reshape(-1)))\n",
    "print(np.histogram(v[:,:,1].reshape(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多线程查找每个轨迹起点所在区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6105003\n",
      "sharelist append 0\n",
      "(3210, 2)\n",
      "thread 0: item length = 110\n",
      "thread 1: item length = 110\n",
      "thread 2: item length = 110\n",
      "thread 3: item length = 110\n",
      "thread 4: item length = 110\n",
      "thread 5: item length = 110\n",
      "thread 6: item length = 110\n",
      "thread 7: item length = 110\n",
      "thread 8: item length = 110\n",
      "thread 9: item length = 110\n",
      "thread 10: item length = 110\n",
      "thread 11: item length = 110\n",
      "thread 12: item length = 110\n",
      "thread 13: item length = 110\n",
      "thread 14: item length = 110\n",
      "thread 15: item length = 110\n",
      "thread 16: item length = 110\n",
      "thread 17: item length = 110\n",
      "thread 18: item length = 110\n",
      "thread 19: item length = 110\n",
      "thread 20: item length = 110\n",
      "thread 21: item length = 110\n",
      "thread 22: item length = 110\n",
      "thread 23: item length = 110\n",
      "thread 24: item length = 110\n",
      "thread 25: item length = 110\n",
      "thread 26: item length = 110\n",
      "thread 27: item length = 110\n",
      "thread 28: item length = 130\n",
      "end over\n",
      "(3210, 2)\n",
      "thread 0: item length = 110\n",
      "thread 1: item length = 110\n",
      "thread 2: item length = 110\n",
      "thread 3: item length = 110\n",
      "thread 4: item length = 110\n",
      "thread 5: item length = 110\n",
      "thread 6: item length = 110\n",
      "thread 7: item length = 110\n",
      "thread 8: item length = 110\n",
      "thread 9: item length = 110\n",
      "thread 10: item length = 110\n",
      "thread 11: item length = 110\n",
      "thread 12: item length = 110\n",
      "thread 13: item length = 110\n",
      "thread 14: item length = 110\n",
      "thread 15: item length = 110\n",
      "thread 16: item length = 110\n",
      "thread 17: item length = 110\n",
      "thread 18: item length = 110\n",
      "thread 19: item length = 110\n",
      "thread 20: item length = 110\n",
      "thread 21: item length = 110\n",
      "thread 22: item length = 110\n",
      "thread 23: item length = 110\n",
      "thread 24: item length = 110\n",
      "thread 25: item length = 110\n",
      "thread 26: item length = 110\n",
      "thread 27: item length = 110\n",
      "thread 28: item length = 130\n",
      "start over\n"
     ]
    }
   ],
   "source": [
    "threadnum = 29\n",
    "\n",
    "select_length = len(ride_req_data['ID'])\n",
    "\n",
    "class req_calc_thread(multiprocessing.Process):\n",
    "    def __init__ (self, threadID, start, inputdata, sharelist):\n",
    "        multiprocessing.Process.__init__(self)\n",
    "        self.ID = threadID\n",
    "        self.start_pos = start\n",
    "        self.inputdata = inputdata\n",
    "        self.sharelist = sharelist\n",
    "        print('thread %d: item length = %d' % (threadID, len(self.inputdata)))\n",
    "    \n",
    "    def run(self):\n",
    "        start_time = time.time()\n",
    "        count = 0\n",
    "        for pos in self.inputdata:\n",
    "            #t = extract_time_feat(t[0])\n",
    "            s_pos = find_grid_idx(pos)\n",
    "            self.sharelist[self.start_pos + count] = s_pos\n",
    "            if s_pos == -1: print(pos)\n",
    "            count += 1\n",
    "            if self.ID == threadnum - 1 and count % 1000 == 0:\n",
    "                print(self.ID, count, time.time() - start_time)\n",
    "\n",
    "count = 0\n",
    "m = {}\n",
    "req_zipped = []\n",
    "for i in list(zip(ride_req_data['ID'], ride_req_data['time'], ride_req_data['pos'], ride_req_data['reward'])):\n",
    "    if i[0] not in m:\n",
    "        req_zipped.append(i)\n",
    "        m[i[0]] = 1\n",
    "        \n",
    "print(len(req_zipped))\n",
    "\n",
    "req_zipped = list(zip(ride_req_data['ID'], ride_req_data['time'], ride_req_data['pos'], ride_req_data['reward']))[:select_length]\n",
    "\n",
    "manager = multiprocessing.Manager()\n",
    "sharelist = manager.list()\n",
    "for i in range(len(req_zipped)):\n",
    "    sharelist.append(0)\n",
    "    if i % 10000 == 0:\n",
    "        print('sharelist append %d' % i)\n",
    "\n",
    "threads = []\n",
    "pos = ride_req_data['pos'][:select_length,1]\n",
    "print(pos.shape)\n",
    "for i in range(threadnum):\n",
    "    delta = len(pos) // threadnum\n",
    "    start = delta * i\n",
    "    end = start + delta\n",
    "    if i + 1 == threadnum:\n",
    "        end = len(pos)\n",
    "    #print(i, start, end)\n",
    "    threads.append(req_calc_thread(i, start, pos[start:end], sharelist))\n",
    "    threads[i].start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "print('end over')\n",
    "end_grid = list(sharelist)\n",
    "\n",
    "threads = []\n",
    "pos = ride_req_data['pos'][:select_length,0]\n",
    "print(pos.shape)\n",
    "for i in range(threadnum):\n",
    "    delta = len(pos) // threadnum\n",
    "    start = delta * i\n",
    "    end = start + delta\n",
    "    if i + 1 == threadnum:\n",
    "        end = len(pos)\n",
    "    #print(i, start, end)\n",
    "    threads.append(req_calc_thread(i, start, pos[start:end], sharelist))\n",
    "    threads[i].start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "print('start over')\n",
    "start_grid = list(sharelist)\n",
    "\n",
    "ride_req_data['start_grid'] = start_grid\n",
    "ride_req_data['end_grid'] = end_grid\n",
    "pickle.dump(ride_req_data, open(folder + 'ride_req.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pos', 'ID', 'end_grid', 'grid', 'reward', 'time', 'start_grid'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ride_req_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid_order_count = np.zeros((len(grid_data['ID']) + 1, 31, 24, 7), dtype='int')\n",
    "grid_reward_count = np.zeros((len(grid_data['ID']) + 1, 31, 24, 7), dtype='float')\n",
    "\n",
    "req_zipped = list(zip(ride_req_data['ID'], ride_req_data['start_grid'], ride_req_data['time'], ride_req_data['pos'], ride_req_data['reward']))\n",
    "\n",
    "m = set()\n",
    "\n",
    "for num, [i, s_pos, t, pos, re] in enumerate(req_zipped):\n",
    "    if i in m:\n",
    "        continue\n",
    "    m.add(i)\n",
    "    t = extract_time_feat(t[0])\n",
    "    grid_order_count[s_pos, t[0], t[1], t[2]] += 1\n",
    "    grid_reward_count[s_pos, t[0], t[1], t[2]] += re\n",
    "grid_order_count = grid_order_count[:-1,1:]\n",
    "grid_reward_count = grid_reward_count[:-1,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8518, 30, 24, 7) (8518, 30, 24, 7)\n"
     ]
    }
   ],
   "source": [
    "print(grid_order_count.shape, grid_reward_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_order = np.array(grid_order_count).sum(axis=1)\n",
    "grid_reward = np.array(grid_reward_count).sum(axis=1)\n",
    "grid_order[grid_order == 0] = 1\n",
    "grid_reward /= grid_order\n",
    "grid_order = np.array(grid_order_count).sum(axis=1)\n",
    "pickle.dump({'order': grid_order, 'reward': grid_reward}, open(folder + 'grid_order_reward.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3604 93.05\n",
      "(8518, 24, 7) (8518, 24, 7)\n"
     ]
    }
   ],
   "source": [
    "print(grid_order.max(), grid_reward.max())\n",
    "print(grid_order.shape, grid_reward.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理取消概率数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancel_data = pickle.load(open(folder + 'cancel_prob.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {}\n",
    "for i, p in zip(cancel_data['ID'], cancel_data['prob']):\n",
    "    if i in m.keys():\n",
    "        if (p != m[i]).any():\n",
    "            print(i, p, m[i])\n",
    "            break\n",
    "        continue\n",
    "    m[i] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {}\n",
    "for i, t, pos, re in zip(ride_req_data['ID'], ride_req_data['time'], ride_req_data['pos'], ride_req_data['reward']):\n",
    "    if i in m.keys():\n",
    "        if (t != m[i][0]).any() or (pos != m[i][1]).any() or (re != m[i][2]).any():\n",
    "            print(i, t, pos, re, m[i])\n",
    "            break\n",
    "        continue\n",
    "    m[i] = [t,pos,re]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7065937, 10) 6105003\n"
     ]
    }
   ],
   "source": [
    "print(cancel_data['prob'].shape, len(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = set()\n",
    "# startG, endG, hour, weekday, isweekend, reward, order ETA\n",
    "cancel_train = []\n",
    "L = len(cancel_data['ID'])\n",
    "for i in range(L):\n",
    "    ID = cancel_data['ID'][i]\n",
    "    if ID in m:\n",
    "        continue\n",
    "    m.add(ID)\n",
    "    startG = ride_req_data['start_grid'][i]\n",
    "    endG = ride_req_data['end_grid'][i]\n",
    "    t = ride_req_data['time'][i]\n",
    "    st = extract_time_feat(t[0])\n",
    "    hour = st[1]\n",
    "    weekday = st[2]\n",
    "    isweekend = st[3]\n",
    "    reward = ride_req_data['reward'][i]\n",
    "    ETA = t[1] - t[0]\n",
    "    prob = cancel_data['prob'][i]\n",
    "    if startG == -1 or endG == -1:\n",
    "        #print([ride_req_data['pos'][i], endG, hour, weekday, isweekend, reward, ETA, prob])\n",
    "        continue\n",
    "    cancel_train.append([startG, endG, hour, weekday, isweekend, reward, ETA, prob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6104887\n"
     ]
    }
   ],
   "source": [
    "print(len(cancel_train))\n",
    "startG, endG, hour, weekday, isweekend, reward, ETA, prob = list(zip(*cancel_train))\n",
    "GID = np.array(list(zip(startG, endG)))\n",
    "splittime = np.array(list(zip(hour, weekday, isweekend)))\n",
    "reward = np.array(reward)\n",
    "ETA = np.array(ETA)\n",
    "prob = np.array(prob)\n",
    "\n",
    "cancel_train = {\n",
    "    'GID': GID,\n",
    "    'time': splittime,\n",
    "    'reward': reward,\n",
    "    'ETA': ETA,\n",
    "    'prob': prob\n",
    "}\n",
    "pickle.dump(cancel_train, open(folder + 'cancel_prob_train.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ETA': array([1710, 2090, 1265, ..., 2145, 1545, 1031]),\n",
       " 'GID': array([[3046, 3944],\n",
       "        [6400, 5081],\n",
       "        [6912, 1720],\n",
       "        ...,\n",
       "        [5422, 6971],\n",
       "        [7839,   60],\n",
       "        [3735, 4176]]),\n",
       " 'prob': array([[0.008606, 0.008098, 0.008355, ..., 0.042079, 0.043802, 0.046584],\n",
       "        [0.117864, 0.126627, 0.134129, ..., 0.210413, 0.227839, 0.237643],\n",
       "        [0.011333, 0.010759, 0.011035, ..., 0.041103, 0.044903, 0.050505],\n",
       "        ...,\n",
       "        [0.008664, 0.009315, 0.009673, ..., 0.046172, 0.050188, 0.056687],\n",
       "        [0.013174, 0.014159, 0.014555, ..., 0.05161 , 0.056076, 0.063198],\n",
       "        [0.012617, 0.010593, 0.010353, ..., 0.058398, 0.070243, 0.084266]]),\n",
       " 'reward': array([ 3.54, 11.7 ,  5.01, ...,  5.27,  5.72,  2.38]),\n",
       " 'time': array([[ 9,  1,  0],\n",
       "        [15,  1,  0],\n",
       "        [20,  1,  0],\n",
       "        ...,\n",
       "        [20,  2,  0],\n",
       "        [18,  2,  0],\n",
       "        [19,  2,  0]])}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancel_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
