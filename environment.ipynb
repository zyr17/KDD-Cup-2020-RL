{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define gym environment for RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from common import find_grid_idx, extract_time_feat, min_gps, max_gps, real_distance, block_number, cuda\n",
    "delta_gps = max_gps - min_gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_folder = 'data/pkl/'\n",
    "rd_data = pickle.load(open(pkl_folder + 'grid_order_reward.pkl', 'rb'))\n",
    "rd_data = np.concatenate([np.expand_dims(rd_data['reward'],2), np.expand_dims(rd_data['order'],2)], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_data = pickle.load(open(pkl_folder + 'carenv_actions.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarEnv:\n",
    "    \"\"\"KDDCup2020 car environment\n",
    "    State: [lat, lon, hour, average_reward, demand]\n",
    "    Action: [lat, lon, ETA, reward, prob]\n",
    "    \n",
    "    Args:\n",
    "        actions: (block_number, 24) list, every item contains actions\n",
    "                 [startlat, startlon, endlat, endlon, ETA, reward, prob] with shape (x,) except prob \n",
    "                 with shape (x,10)\n",
    "        reward_demand: shape (block_number, 2), means average reward and average demand    TODO: use NN to predict?\n",
    "        random_seed: initial seed\n",
    "        choose_ratio: select how much actions\n",
    "        choose_max: select as maximum how much actions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, actions, reward_demand, random_seed = 0, choose_ratio = 0.6, choose_max = 12):\n",
    "        self.actions = actions\n",
    "        self.reward_demand = reward_demand\n",
    "        self.rng = np.random.RandomState(random_seed)\n",
    "        self.now_time = None\n",
    "        self.now_state = None\n",
    "        self.now_actions = None\n",
    "        self.choose_ratio = choose_ratio\n",
    "        self.choose_max = choose_max\n",
    "        self.fail_waste = 600.0\n",
    "        self.is_reset = False\n",
    "        #self.reset()\n",
    "        \n",
    "    def _get_reward_demand(self, s):\n",
    "        return self.reward_demand[int(s[0] * block_number[0]) * block_number[1] + int(s[1] * block_number[1]), s[2]]\n",
    "        \n",
    "    def _select_action(self):\n",
    "        default_action = [np.array([self.now_state[0]]), np.array([self.now_state[1]]), \n",
    "                          np.array([self.now_state[0]]), np.array([self.now_state[1]]), \n",
    "                          np.array([0]), np.array([0]), np.array([1.0])]\n",
    "        pos = (block_number * self.now_state[:2]).astype(int)\n",
    "        expand = 1\n",
    "        t_expand = 1\n",
    "        alla = []\n",
    "        for i in range(-expand, expand + 1):\n",
    "            for j in range(-expand, expand + 1):\n",
    "                for k in range(-t_expand, t_expand + 1):\n",
    "                    k = (k + self.now_state[2] + 24) % 24\n",
    "                    nowp = [i, j] + pos\n",
    "                    if (nowp < 0).any() or (nowp >= block_number).any():\n",
    "                        continue\n",
    "                    block_idx = (nowp * [block_number[1], 1]).sum()\n",
    "                    #print(block_idx, k)\n",
    "                    if len(self.actions[block_idx][k][0]) > 0:\n",
    "                        alla.append(self.actions[block_idx][k])\n",
    "        alla = [np.concatenate(x) for x in zip(*alla)]\n",
    "        if len(alla[0]) == 0:\n",
    "            return [default_action]\n",
    "        choose_num = int(self.rng.normal(self.choose_ratio, 2) * len(alla[0]))\n",
    "        if choose_num <= 0:\n",
    "            choose_num = 1\n",
    "        if choose_num > len(alla[0]):\n",
    "            choose_num = len(alla[0])\n",
    "        if choose_num >= self.choose_max:\n",
    "            choose_num = self.choose_max - 1\n",
    "        choose = self.rng.choice(len(alla[0]), choose_num, replace = False)\n",
    "        alla = [x[choose] for x in alla]\n",
    "        gps = np.stack(alla[:2]).transpose(1, 0)\n",
    "        gps = (gps - self.now_state[:2]) * real_distance\n",
    "        gps = (gps ** 2).sum(axis=1) ** 0.5\n",
    "        alla[4] += (gps / 5.7).astype(int) # add time driving to there\n",
    "        gps = (gps / 200).astype(int)\n",
    "        gps[gps > 9] = 9\n",
    "        alla[-1] = np.choose(gps, alla[-1].T)\n",
    "        #print(gps, alla[-1])\n",
    "        for i in range(len(alla)):\n",
    "            alla[i] = np.append(alla[i], default_action[i])\n",
    "        return alla\n",
    "    \n",
    "    def reset(self):\n",
    "        while True:\n",
    "            self.now_time = self.rng.randint(24) * 3600\n",
    "            s = [*self.rng.random(2), time.localtime(self.now_time).tm_hour]\n",
    "            s += self._get_reward_demand(s).tolist()\n",
    "            self.now_state = s\n",
    "            a = self._select_action()\n",
    "            if len(a) == 1:\n",
    "                continue\n",
    "            self.now_actions = a\n",
    "            break\n",
    "        self.is_reset = True\n",
    "        return self.now_state, {'time': self.now_time}\n",
    "    \n",
    "    def step(self, action):\n",
    "        assert(self.is_reset)\n",
    "        a = [x[action] for x in self.now_actions][2:]\n",
    "        if self.rng.random() < a[4]:\n",
    "            reward = 0\n",
    "            length = self.fail_waste # waste some time\n",
    "            self.now_time += length\n",
    "            self.now_state = [*self.now_state[:2], time.localtime(self.now_time).tm_hour]\n",
    "            s = self.now_state\n",
    "            s += self._get_reward_demand(s).tolist()\n",
    "            self.now_actions = self._select_action()\n",
    "            return s, reward, length, {'time': self.now_time}\n",
    "        reward = a[3]\n",
    "        length = a[2]\n",
    "        self.now_time = self.now_time + length\n",
    "        self.now_state = [*a[:2], time.localtime(self.now_time).tm_hour]\n",
    "        s = self.now_state\n",
    "        s += self._get_reward_demand(s).tolist()\n",
    "        self.now_actions = self._select_action()\n",
    "        return s, reward, length, {'time': self.now_time}\n",
    "    def get_actions(self):\n",
    "        assert(self.is_reset)\n",
    "        return self.now_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvWorker(multiprocessing.Process):\n",
    "    def __init__(self, env, envargs, pipe1, pipe2):\n",
    "        multiprocessing.Process.__init__(self, daemon = True)\n",
    "        self.env = env(*envargs)\n",
    "        self.pipe = pipe1\n",
    "        self.pipe2 = pipe2\n",
    "    \n",
    "    def run(self):\n",
    "        self.pipe2.close()\n",
    "        while True:\n",
    "            try:\n",
    "                cmd, data = self.pipe.recv()\n",
    "                if cmd == 'step':\n",
    "                    self.pipe.send(self.env.step(data))\n",
    "                elif cmd == 'get_actions':\n",
    "                    self.pipe.send(self.env.get_actions())\n",
    "                elif cmd == 'close':\n",
    "                    self.pipe.close()\n",
    "                    break\n",
    "                elif cmd == 'reset':\n",
    "                    self.pipe.send(self.env.reset())\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "            except EOFError:\n",
    "                break\n",
    "                \n",
    "class EnvVecs:\n",
    "    def __init__(self, env_class, n_envs, env_args, arg_seed_pos = -1, seed = 0):\n",
    "        self.waiting = False\n",
    "        self.closed = False\n",
    "\n",
    "        self.remotes, self.work_remotes = zip(*[multiprocessing.Pipe(duplex=True) for _ in range(n_envs)])\n",
    "        self.processes = []\n",
    "        for work_remote, remote in zip(self.work_remotes, self.remotes):\n",
    "            #args = (env_class, work_remote, remote)\n",
    "            # daemon=True: if the main process crashes, we should not cause things to hang\n",
    "            args = list(env_args)\n",
    "            if arg_seed_pos != -1:\n",
    "                args[arg_seed_pos] = seed\n",
    "                seed += 1\n",
    "            process = EnvWorker(env_class, args, work_remote, remote)  # pytype:disable=attribute-error\n",
    "            process.start()\n",
    "            self.processes.append(process)\n",
    "            work_remote.close()\n",
    "        self.is_reset = False\n",
    "\n",
    "    def step_async(self, actions):\n",
    "        for remote, action in zip(self.remotes, actions):\n",
    "            remote.send(('step', action))\n",
    "        self.waiting = True\n",
    "\n",
    "    def step_wait(self):\n",
    "        results = [remote.recv() for remote in self.remotes]\n",
    "        self.waiting = False\n",
    "        obs, rews, lengths, infos = zip(*results)\n",
    "        self._get_actions()\n",
    "        return self._flatten_obs(obs), np.stack(rews), np.stack(lengths), self._flatten_info(infos)\n",
    "\n",
    "    def step(self, actions):\n",
    "        assert(self.is_reset)\n",
    "        self.step_async(actions)\n",
    "        return self.step_wait()\n",
    "    \n",
    "    def close(self):\n",
    "        if self.closed:\n",
    "            return\n",
    "        if self.waiting:\n",
    "            for remote in self.remotes:\n",
    "                remote.recv()\n",
    "        for remote in self.remotes:\n",
    "            remote.send(('close', None))\n",
    "        for process in self.processes:\n",
    "            process.join()\n",
    "        self.closed = True\n",
    "    \n",
    "    def _get_actions(self):\n",
    "        for remote in self.remotes:\n",
    "            remote.send(('get_actions', None))\n",
    "        self.actions = [remote.recv() for remote in self.remotes]\n",
    "\n",
    "    def get_actions(self):\n",
    "        assert(self.is_reset)\n",
    "        return self.actions\n",
    "        \n",
    "    def reset(self):\n",
    "        for remote in self.remotes:\n",
    "            remote.send(('reset', None))\n",
    "        results = [remote.recv() for remote in self.remotes]\n",
    "        obs, infos = zip(*results)\n",
    "        self.is_reset = True\n",
    "        self._get_actions()\n",
    "        return self._flatten_obs(obs), self._flatten_info(infos)\n",
    "    \n",
    "    def _flatten_obs(self, obs):\n",
    "        #print(obs)\n",
    "        obs = list(zip(*obs))\n",
    "        obs = list(map(lambda x:np.stack(x), obs))\n",
    "        #print(obs)\n",
    "        return obs\n",
    "    \n",
    "    def _flatten_info(self, info):\n",
    "        if len(info) == 0:\n",
    "            return {}\n",
    "        res = {}\n",
    "        for key in info[0].keys():\n",
    "            res[key] = np.stack([x[key] for x in info])\n",
    "        return res\n",
    "\n",
    "def get_carenvvec(number):\n",
    "    return EnvVecs(CarEnv, number, (action_data, rd_data, 0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = CarEnv(action_data, rd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.5928446182250183, 0.8442657485810173, 20, 8.965, 2.0], {'time': 43200})\n",
      "[array([0.5738    , 0.57934   , 0.59217   , 0.588904  , 0.612006  ,\n",
      "       0.59296   , 0.575324  , 0.586206  , 0.56336   , 0.58534   ,\n",
      "       0.5738    , 0.59284462]), array([0.83273333, 0.86437778, 0.84631778, 0.86904444, 0.83994222,\n",
      "       0.84691111, 0.83899778, 0.86312444, 0.82107333, 0.86264444,\n",
      "       0.83273333, 0.84426575]), array([0.42086   , 0.424858  , 0.42918   , 0.7751    , 0.49718   ,\n",
      "       0.68324   , 0.55118   , 0.4824    , 0.57424   , 0.52422   ,\n",
      "       0.52632   , 0.59284462]), array([0.57      , 0.54268444, 0.50726667, 0.44433333, 0.56582222,\n",
      "       0.39708889, 0.55628889, 0.30939778, 0.43475556, 0.56164444,\n",
      "       0.56731111, 0.84426575]), array([3097, 2168, 3929, 3337, 2331, 2921, 1906, 3474, 3165, 5242, 1955,\n",
      "          0]), array([ 9.72, 10.05, 12.54, 15.63,  8.38, 14.06,  6.56, 18.56, 10.78,\n",
      "       11.63,  6.28,  0.  ]), array([0.052844, 0.050365, 0.168158, 0.130051, 0.055499, 0.249974,\n",
      "       0.035833, 0.127857, 0.079762, 0.044078, 0.056043, 1.      ])]\n",
      "([0.4208600000000047, 0.5699999999999988, 20, 4.073552168815943, 853.0], 9.72, 3097, {'time': 46297})\n"
     ]
    }
   ],
   "source": [
    "print(ce.reset())\n",
    "print(ce.get_actions())\n",
    "print(ce.step(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.44084 , 0.43052 , 0.43584 , 0.42646 , 0.44098 , 0.45422 ,\n",
      "       0.44985 , 0.42266 , 0.451182, 0.446218, 0.41524 , 0.42086 ]), array([0.54700222, 0.58884444, 0.5672    , 0.56504444, 0.54806667,\n",
      "       0.54604889, 0.56584444, 0.56675111, 0.54472222, 0.54980222,\n",
      "       0.54482222, 0.57      ]), array([0.5516  , 0.5164  , 0.51378 , 0.48084 , 0.49344 , 0.48656 ,\n",
      "       0.52864 , 0.498402, 0.4864  , 0.50174 , 0.538624, 0.42086 ]), array([0.46753333, 0.49766667, 0.561     , 0.77008889, 0.65846667,\n",
      "       0.56446667, 0.57155556, 0.57826667, 0.5712    , 0.59786667,\n",
      "       0.59388444, 0.57      ]), array([1839, 1787,  760, 1198, 1083,  942, 1576,  897,  913, 1229, 1207,\n",
      "          0]), array([4.01, 3.76, 2.36, 4.29, 3.4 , 1.82, 2.91, 2.45, 1.83, 2.3 , 3.49,\n",
      "       0.  ]), array([0.069046, 0.038289, 0.015818, 0.019119, 0.0474  , 0.365834,\n",
      "       0.03859 , 0.011601, 0.072534, 0.051171, 0.044322, 1.      ])]\n",
      "([0.5516000000000076, 0.46753333333333474, 21, 3.3674456468752973, 10257.0], 4.01, 1839, {'time': 48136})\n"
     ]
    }
   ],
   "source": [
    "print(ce.get_actions())\n",
    "print(ce.step(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = get_carenvvec(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([array([0.59284462, 0.99718481, 0.18508208, 0.07072488]), array([0.84426575, 0.93255736, 0.93154087, 0.83994904]), array([20, 13, 16, 18]), array([ 8.965, 19.31 ,  0.   ,  0.   ]), array([2., 1., 0., 0.])], {'time': array([43200, 18000, 28800, 36000])})\n"
     ]
    }
   ],
   "source": [
    "print(ev.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([0.71686, 0.68848]), array([0.47857778, 0.49515556]), array([0.46846, 0.68848]), array([0.52877778, 0.49515556]), array([1601,    0]), array([9.4, 0. ]), array([0.037821, 1.      ])], [array([0.79738, 0.81958]), array([0.27688889, 0.2668    ]), array([0.47304, 0.81958]), array([0.54555778, 0.2668    ]), array([2435,    0]), array([14.73,  0.  ]), array([0.139955, 1.      ])], [array([0.606174, 0.633384, 0.60598 , 0.6273  , 0.636892, 0.6059  ,\n",
      "       0.608738, 0.63446 , 0.61336 , 0.61886 , 0.630118, 0.63506 ]), array([0.48941778, 0.45654889, 0.48164444, 0.4726    , 0.46532444,\n",
      "       0.49017778, 0.48791111, 0.45328889, 0.48666667, 0.4416    ,\n",
      "       0.46366444, 0.46155556]), array([0.52158 , 0.85728 , 0.673258, 0.67582 , 0.55558 , 0.75244 ,\n",
      "       0.59726 , 0.67842 , 0.57428 , 0.57066 , 0.48446 , 0.63506 ]), array([0.4604    , 0.45708889, 0.34146667, 0.5196    , 0.42435556,\n",
      "       0.52944444, 0.55902222, 0.516     , 0.50526667, 0.46153333,\n",
      "       0.48115556, 0.46155556]), array([1301, 1748, 1546,  709, 1518, 1473,  940,  843,  889,  694,  907,\n",
      "          0]), array([3.44, 7.46, 5.97, 2.14, 4.07, 5.26, 2.97, 2.96, 2.1 , 2.04, 5.03,\n",
      "       0.  ]), array([0.024718, 0.269493, 0.034922, 0.01668 , 0.002451, 0.062384,\n",
      "       0.011507, 0.007447, 0.032601, 0.032111, 0.00813 , 1.      ])], [array([0.5412 , 0.54436]), array([0.556     , 0.57237778]), array([0.32928, 0.54436]), array([0.66862222, 0.57237778]), array([1747,    0]), array([8.34, 0.  ]), array([0.031925, 1.      ])]]\n",
      "([array([0.46846, 0.47304, 0.52158, 0.32928]), array([0.52877778, 0.54555778, 0.4604    , 0.66862222]), array([ 4, 23,  0,  4]), array([3.69226744, 4.45969274, 4.52971429, 8.17461538]), array([ 172.,  358., 1155.,   26.])], array([ 9.4 , 14.73,  3.44,  8.34]), array([1601, 2435, 1301, 1747]), {'time': array([73054., 56533., 60747., 74139.])})\n"
     ]
    }
   ],
   "source": [
    "print(ev.get_actions())\n",
    "print(ev.step([0] * len(ev.processes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
